{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle_MNIST_Digits_ANN_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHun7U6OTRib",
        "colab_type": "code",
        "outputId": "5bdb2308-8248-4083-e6d4-e3d1dd8eb81c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive\n",
        "%ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive\n",
            "\u001b[0m\u001b[01;34m'My Drive'\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-HPwu12Tioa",
        "colab_type": "code",
        "outputId": "51c0e5e8-66b1-4bbf-b309-c56f233099a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "# See https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "  random_image_cpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_cpu = tf.layers.conv2d(random_image_cpu, 32, 7)\n",
        "  net_cpu = tf.reduce_sum(net_cpu)\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "  random_image_gpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_gpu = tf.layers.conv2d(random_image_gpu, 32, 7)\n",
        "  net_gpu = tf.reduce_sum(net_gpu)\n",
        "\n",
        "sess = tf.Session(config=config)\n",
        "\n",
        "# Test execution once to detect errors early.\n",
        "try:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "except tf.errors.InvalidArgumentError:\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise\n",
        "\n",
        "def cpu():\n",
        "  sess.run(net_cpu)\n",
        "  \n",
        "def gpu():\n",
        "  sess.run(net_gpu)\n",
        "  \n",
        "# Runs the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "3.568735851999975\n",
            "GPU (s):\n",
            "0.16955588400003307\n",
            "GPU speedup over CPU: 21x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEL2mBzfTHYa",
        "colab_type": "text"
      },
      "source": [
        "[](http://)#### This is a simple ANN to classify digits. Tuned parameters are Optimization Kernel, Learning Rate, trails to add 1or2 hidden layers and lastly adding drop out to achieve 98+% accuracy. A basic ANN notebook for submission Test Prediction on Digits. \n",
        "\n",
        "Later down below, images of Fashion items read (Fashion_MNIST dataset in Keras) and tried with CNN. For practice and tutorial for beginners. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uPiiFR5acTW",
        "colab_type": "code",
        "trusted": true,
        "outputId": "04688cbc-62cf-4a89-8f2c-457f4db2126c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1212)\n",
        "\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "from keras.layers import Dense\n",
        "from keras import optimizers"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBD6OsQFUsaa",
        "colab_type": "code",
        "outputId": "876517b8-9671-4728-82b7-b3036eeeb390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pwd\n",
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive\n",
            "'My Drive'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIUAmBMMAizK",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv('/gdrive/My Drive/MyLearning/MLDLAIPython/Data/TextData/MNIST_train.csv')\n",
        "df_test = pd.read_csv('/gdrive/My Drive/MyLearning/MLDLAIPython/Data/TextData/MNISTtest.csv')\n",
        "#images in these datasets are already flattened and in Machine readable format"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzTZlIlXFvZD",
        "colab_type": "code",
        "outputId": "c7038fb2-1b3e-4fc2-ca4f-0fc769cb68b0",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "df_train.head() # 784 features, 1 label"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
              "0      1       0       0       0  ...         0         0         0         0\n",
              "1      0       0       0       0  ...         0         0         0         0\n",
              "2      1       0       0       0  ...         0         0         0         0\n",
              "3      4       0       0       0  ...         0         0         0         0\n",
              "4      0       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY9CoeuXGFmg",
        "colab_type": "code",
        "outputId": "36579418-8501-4044-bfe8-02dc328f9007",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_features = df_train.iloc[:, 1:785]\n",
        "df_label = df_train.iloc[:, 0]\n",
        "\n",
        "X_test = df_test.iloc[:, 0:784]\n",
        "\n",
        "print(X_test.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCuTawlJGLp_",
        "colab_type": "code",
        "trusted": true,
        "outputId": "d1892caf-d6b5-4b3d-ab15-9ff50a2741dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_cv, y_train, y_cv = train_test_split(df_features, df_label, test_size = 0.2, random_state = 42)\n",
        "X_train = X_train.values.reshape(33600, 784) #(33600, 784)\n",
        "X_cv = X_cv.values.reshape(8400, 784) #(8400, 784)\n",
        "X_test = X_test.as_matrix().reshape(28000, 784)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "h1NX580-THZE",
        "colab_type": "code",
        "outputId": "8e72d72e-00f8-494c-9a8a-ae7d113f76bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape, X_cv.shape, y_train.shape, X_test.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((33600, 784), (8400, 784), (33600,), (28000, 784))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvGB1SvdGRoW",
        "colab_type": "code",
        "outputId": "814c4a13-a29c-42fe-8ba0-f4d1ecc61571",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print((min(X_train[1]), max(X_train[1])))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, 254)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzjszcx3GZVW",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "# Feature Normalization \n",
        "X_train = X_train.astype('float32'); \n",
        "X_cv    = X_cv.astype('float32'); \n",
        "X_test  = X_test.astype('float32')\n",
        "X_train /= 255; \n",
        "X_cv    /= 255; \n",
        "X_test  /= 255\n",
        "\n",
        "# Convert labels to One Hot Encoded\n",
        "num_digits = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_digits)\n",
        "y_cv = keras.utils.to_categorical(y_cv, num_digits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BJW1LMZcTHZP",
        "colab_type": "code",
        "outputId": "a690f486-e323-4ae8-8ef5-c5a5d21fbacc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape, X_cv.shape, y_train.shape, X_test.shape, y_cv.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((33600, 784), (8400, 784), (33600, 10), (28000, 784), (8400, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1PQXLg3GjtX",
        "colab_type": "code",
        "outputId": "da0d8ac9-c90f-45a8-d645-55d16a52f0f1",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Printing 2 examples of labels after conversion\n",
        "print(y_train[0]) # 2\n",
        "print(y_train[3]) # 7"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_jLHqBNG02H",
        "colab_type": "text"
      },
      "source": [
        "<font color=red size = 6>\n",
        "  Model Fitting <br>\n",
        "  <font color=brown size = 4>\n",
        "We proceed by fitting several simple neural network models using Keras (with TensorFlow as our backend) and collect their accuracy. The model that performs the best on the validation set will be used as the model of choice for the competition.\n",
        "<font color=red size = 6>\n",
        "Model 1: Simple Neural Network with 4 layers (300, 100, 100, 200)\n",
        "<font color=brown size = 4>\n",
        "In our first model, we will use the Keras library to train a neural network with the activation function set as ReLu. To determine which class to output, we will rely on the SoftMax function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFAP9bmdGtyS",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "# Input Parameters\n",
        "n_input = 784 # number of features\n",
        "n_hidden_1 = 300\n",
        "n_hidden_2 = 100\n",
        "n_hidden_3 = 100\n",
        "n_hidden_4 = 200\n",
        "num_digits = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1astNyoHKg0",
        "colab_type": "code",
        "trusted": true,
        "outputId": "6f469535-0c14-4d9f-e6a5-85a98137a313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "Inp = Input(shape=(784,))\n",
        "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
        "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
        "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
        "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
        "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEIPasO2HPBM",
        "colab_type": "code",
        "outputId": "266c8656-d34e-4318-e6c1-15b7bb8dfad9",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# Our model would have '6' layers - input layer, 4 hidden layer and 1 output layer\n",
        "model = Model(Inp, output)\n",
        "model.summary() # We have 297,910 parameters to estimate"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "Hidden_Layer_1 (Dense)       (None, 300)               235500    \n",
            "_________________________________________________________________\n",
            "Hidden_Layer_2 (Dense)       (None, 100)               30100     \n",
            "_________________________________________________________________\n",
            "Hidden_Layer_3 (Dense)       (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "Hidden_Layer_4 (Dense)       (None, 200)               20200     \n",
            "_________________________________________________________________\n",
            "Output_Layer (Dense)         (None, 10)                2010      \n",
            "=================================================================\n",
            "Total params: 297,910\n",
            "Trainable params: 297,910\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoBgqKXbHUEQ",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "# Insert Hyperparameters\n",
        "learning_rate = 0.1\n",
        "training_epochs = 20\n",
        "batch_size = 100\n",
        "sgd = optimizers.SGD(lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fdf4AQkMHf44",
        "colab_type": "code",
        "trusted": true,
        "outputId": "a6a029be-225c-419a-da20-fafb128f4033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# We rely on the plain vanilla Stochastic Gradient Descent as our optimizing methodology\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0wAzvQGHkwi",
        "colab_type": "code",
        "outputId": "d0c28c05-6a22-42a9-ff75-f9f534f26a54",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        }
      },
      "source": [
        "history1 = model.fit(X_train, y_train,\n",
        "                     batch_size = batch_size,\n",
        "                     epochs = training_epochs,\n",
        "                     verbose = 2,\n",
        "                     validation_data=(X_cv, y_cv))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "Train on 33600 samples, validate on 8400 samples\n",
            "Epoch 1/20\n",
            " - 3s - loss: 1.8533 - acc: 0.4954 - val_loss: 1.0049 - val_acc: 0.7668\n",
            "Epoch 2/20\n",
            " - 2s - loss: 0.6461 - acc: 0.8321 - val_loss: 0.4725 - val_acc: 0.8657\n",
            "Epoch 3/20\n",
            " - 2s - loss: 0.4057 - acc: 0.8847 - val_loss: 0.3679 - val_acc: 0.8935\n",
            "Epoch 4/20\n",
            " - 2s - loss: 0.3347 - acc: 0.9032 - val_loss: 0.3300 - val_acc: 0.9002\n",
            "Epoch 5/20\n",
            " - 2s - loss: 0.2962 - acc: 0.9137 - val_loss: 0.2956 - val_acc: 0.9136\n",
            "Epoch 6/20\n",
            " - 2s - loss: 0.2668 - acc: 0.9227 - val_loss: 0.2716 - val_acc: 0.9208\n",
            "Epoch 7/20\n",
            " - 2s - loss: 0.2442 - acc: 0.9281 - val_loss: 0.2686 - val_acc: 0.9204\n",
            "Epoch 8/20\n",
            " - 2s - loss: 0.2248 - acc: 0.9339 - val_loss: 0.2369 - val_acc: 0.9319\n",
            "Epoch 9/20\n",
            " - 2s - loss: 0.2085 - acc: 0.9390 - val_loss: 0.2268 - val_acc: 0.9350\n",
            "Epoch 10/20\n",
            " - 2s - loss: 0.1948 - acc: 0.9435 - val_loss: 0.2108 - val_acc: 0.9407\n",
            "Epoch 11/20\n",
            " - 2s - loss: 0.1814 - acc: 0.9473 - val_loss: 0.2011 - val_acc: 0.9426\n",
            "Epoch 12/20\n",
            " - 2s - loss: 0.1704 - acc: 0.9500 - val_loss: 0.1922 - val_acc: 0.9440\n",
            "Epoch 13/20\n",
            " - 2s - loss: 0.1608 - acc: 0.9540 - val_loss: 0.1810 - val_acc: 0.9474\n",
            "Epoch 14/20\n",
            " - 2s - loss: 0.1505 - acc: 0.9572 - val_loss: 0.1758 - val_acc: 0.9477\n",
            "Epoch 15/20\n",
            " - 2s - loss: 0.1425 - acc: 0.9581 - val_loss: 0.1674 - val_acc: 0.9512\n",
            "Epoch 16/20\n",
            " - 2s - loss: 0.1353 - acc: 0.9606 - val_loss: 0.1637 - val_acc: 0.9523\n",
            "Epoch 17/20\n",
            " - 2s - loss: 0.1276 - acc: 0.9629 - val_loss: 0.1580 - val_acc: 0.9530\n",
            "Epoch 18/20\n",
            " - 2s - loss: 0.1208 - acc: 0.9654 - val_loss: 0.1573 - val_acc: 0.9518\n",
            "Epoch 19/20\n",
            " - 2s - loss: 0.1153 - acc: 0.9668 - val_loss: 0.1468 - val_acc: 0.9570\n",
            "Epoch 20/20\n",
            " - 2s - loss: 0.1093 - acc: 0.9690 - val_loss: 0.1451 - val_acc: 0.9590\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ywVSg9WfTHZ9",
        "colab_type": "code",
        "outputId": "8b8bc0c0-6b5c-4bde-fa33-baa6b18df197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "_, val_acc1 = model.evaluate(X_cv, y_cv)\n",
        "print (val_acc1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8400/8400 [==============================] - 1s 60us/step\n",
            "0.959047619047619\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D_rc2N0Il_n",
        "colab_type": "text"
      },
      "source": [
        "<font color=blue size = 4> \n",
        "Using a 4 layer neural network with:\n",
        "20 training epochs\n",
        "A training batch size of 100\n",
        "Hidden layers set as (300, 100, 100, 200)\n",
        "Learning rate of 0.1\n",
        "Achieved Validation Accuracy (score) of around 95%. Do not consider Train Accuracy as it would(should) be close to 100%, since the model is getting trainned and exposed to all the Training data. We should concentrate on validation accuracy as that model has not seen that data. \n",
        "<br><font color=red size = 4>\n",
        "Can we do better if we were to change the optimizer? To find out, we use the Adam optimizer for our second model, while maintaining the same parameter values for all other parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGW8AvTBHx_Y",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "Inp = Input(shape=(784,))\n",
        "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
        "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
        "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
        "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
        "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)\n",
        "\n",
        "# We rely on ADAM as our optimizing methodology\n",
        "adam = keras.optimizers.Adam(lr=learning_rate)\n",
        "model2 = Model(Inp, output)\n",
        "\n",
        "model2.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJqouG8zI4mg",
        "colab_type": "code",
        "outputId": "d3c98700-148e-48c9-d607-4143408a9188",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "history2 = model2.fit(X_train, y_train,\n",
        "                      batch_size = batch_size,\n",
        "                      epochs = training_epochs,\n",
        "                      verbose = 2,\n",
        "                      validation_data=(X_cv, y_cv))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 33600 samples, validate on 8400 samples\n",
            "Epoch 1/20\n",
            " - 3s - loss: 0.3423 - acc: 0.8979 - val_loss: 0.1876 - val_acc: 0.9444\n",
            "Epoch 2/20\n",
            " - 3s - loss: 0.1234 - acc: 0.9617 - val_loss: 0.1393 - val_acc: 0.9596\n",
            "Epoch 3/20\n",
            " - 3s - loss: 0.0829 - acc: 0.9746 - val_loss: 0.1041 - val_acc: 0.9675\n",
            "Epoch 4/20\n",
            " - 3s - loss: 0.0572 - acc: 0.9815 - val_loss: 0.1072 - val_acc: 0.9686\n",
            "Epoch 5/20\n",
            " - 3s - loss: 0.0446 - acc: 0.9854 - val_loss: 0.0933 - val_acc: 0.9732\n",
            "Epoch 6/20\n",
            " - 3s - loss: 0.0349 - acc: 0.9888 - val_loss: 0.1014 - val_acc: 0.9704\n",
            "Epoch 7/20\n",
            " - 3s - loss: 0.0286 - acc: 0.9899 - val_loss: 0.1100 - val_acc: 0.9711\n",
            "Epoch 8/20\n",
            " - 3s - loss: 0.0309 - acc: 0.9907 - val_loss: 0.1292 - val_acc: 0.9667\n",
            "Epoch 9/20\n",
            " - 3s - loss: 0.0236 - acc: 0.9923 - val_loss: 0.0952 - val_acc: 0.9745\n",
            "Epoch 10/20\n",
            " - 3s - loss: 0.0194 - acc: 0.9939 - val_loss: 0.1235 - val_acc: 0.9694\n",
            "Epoch 11/20\n",
            " - 3s - loss: 0.0201 - acc: 0.9933 - val_loss: 0.1270 - val_acc: 0.9679\n",
            "Epoch 12/20\n",
            " - 3s - loss: 0.0145 - acc: 0.9953 - val_loss: 0.1590 - val_acc: 0.9677\n",
            "Epoch 13/20\n",
            " - 3s - loss: 0.0208 - acc: 0.9934 - val_loss: 0.1272 - val_acc: 0.9707\n",
            "Epoch 14/20\n",
            " - 3s - loss: 0.0166 - acc: 0.9946 - val_loss: 0.1093 - val_acc: 0.9755\n",
            "Epoch 15/20\n",
            " - 3s - loss: 0.0122 - acc: 0.9961 - val_loss: 0.1379 - val_acc: 0.9731\n",
            "Epoch 16/20\n",
            " - 3s - loss: 0.0103 - acc: 0.9963 - val_loss: 0.1303 - val_acc: 0.9729\n",
            "Epoch 17/20\n",
            " - 3s - loss: 0.0179 - acc: 0.9943 - val_loss: 0.1143 - val_acc: 0.9723\n",
            "Epoch 18/20\n",
            " - 3s - loss: 0.0179 - acc: 0.9945 - val_loss: 0.1176 - val_acc: 0.9744\n",
            "Epoch 19/20\n",
            " - 3s - loss: 0.0083 - acc: 0.9974 - val_loss: 0.1424 - val_acc: 0.9721\n",
            "Epoch 20/20\n",
            " - 3s - loss: 0.0155 - acc: 0.9952 - val_loss: 0.1258 - val_acc: 0.9711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VSxBLiZZTHaY",
        "colab_type": "code",
        "outputId": "d48ab717-a0aa-4eb2-f4b4-dd2f7a70cd45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "_, val_acc2 = model2.evaluate(X_cv, y_cv)\n",
        "print (val_acc2)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8400/8400 [==============================] - 0s 57us/step\n",
            "0.9710714285714286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztnHN71lJQek",
        "colab_type": "text"
      },
      "source": [
        "<font color=green size=4>\n",
        "  As it turns out, it does appear to be the case that the optimizer plays a crucial part in the validation score. In particular, the model which relies on 'Adam' as its optimizer tend to perform 1.5 - 2.5% better on average. Going forward, we will use 'Adam' as our optimizer of choice.\n",
        "<br><font color=brown size=4>\n",
        "What if we changed the learning rate from 0.1 to 0.01, or 0.5? Will it have any impact on the accuracy? Model 2A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEG1R2SUI8Gl",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "Inp = Input(shape=(784,))\n",
        "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
        "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
        "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
        "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
        "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)\n",
        "\n",
        "learning_rate = 0.01\n",
        "adam = keras.optimizers.Adam(lr=learning_rate)\n",
        "model2a = Model(Inp, output)\n",
        "\n",
        "model2a.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQuIfkvQJbSW",
        "colab_type": "code",
        "outputId": "cb62b605-d18a-4909-fac9-fef91cad1bfe",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "history2a = model2a.fit(X_train, y_train,\n",
        "                        batch_size = batch_size,\n",
        "                        epochs = training_epochs,\n",
        "                        verbose = 2,\n",
        "                        validation_data=(X_cv, y_cv))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 33600 samples, validate on 8400 samples\n",
            "Epoch 1/20\n",
            " - 3s - loss: 0.3340 - acc: 0.8996 - val_loss: 0.1573 - val_acc: 0.9527\n",
            "Epoch 2/20\n",
            " - 3s - loss: 0.1248 - acc: 0.9627 - val_loss: 0.1349 - val_acc: 0.9581\n",
            "Epoch 3/20\n",
            " - 3s - loss: 0.0797 - acc: 0.9762 - val_loss: 0.1383 - val_acc: 0.9590\n",
            "Epoch 4/20\n",
            " - 3s - loss: 0.0596 - acc: 0.9808 - val_loss: 0.0969 - val_acc: 0.9704\n",
            "Epoch 5/20\n",
            " - 3s - loss: 0.0449 - acc: 0.9860 - val_loss: 0.1166 - val_acc: 0.9675\n",
            "Epoch 6/20\n",
            " - 3s - loss: 0.0359 - acc: 0.9883 - val_loss: 0.1217 - val_acc: 0.9673\n",
            "Epoch 7/20\n",
            " - 3s - loss: 0.0301 - acc: 0.9903 - val_loss: 0.0966 - val_acc: 0.9750\n",
            "Epoch 8/20\n",
            " - 3s - loss: 0.0231 - acc: 0.9927 - val_loss: 0.1129 - val_acc: 0.9712\n",
            "Epoch 9/20\n",
            " - 3s - loss: 0.0225 - acc: 0.9926 - val_loss: 0.1155 - val_acc: 0.9692\n",
            "Epoch 10/20\n",
            " - 3s - loss: 0.0217 - acc: 0.9928 - val_loss: 0.1467 - val_acc: 0.9669\n",
            "Epoch 11/20\n",
            " - 3s - loss: 0.0221 - acc: 0.9928 - val_loss: 0.1114 - val_acc: 0.9739\n",
            "Epoch 12/20\n",
            " - 3s - loss: 0.0185 - acc: 0.9943 - val_loss: 0.1120 - val_acc: 0.9712\n",
            "Epoch 13/20\n",
            " - 3s - loss: 0.0201 - acc: 0.9935 - val_loss: 0.1225 - val_acc: 0.9736\n",
            "Epoch 14/20\n",
            " - 3s - loss: 0.0118 - acc: 0.9963 - val_loss: 0.1455 - val_acc: 0.9704\n",
            "Epoch 15/20\n",
            " - 3s - loss: 0.0163 - acc: 0.9943 - val_loss: 0.1479 - val_acc: 0.9711\n",
            "Epoch 16/20\n",
            " - 3s - loss: 0.0167 - acc: 0.9946 - val_loss: 0.1312 - val_acc: 0.9715\n",
            "Epoch 17/20\n",
            " - 3s - loss: 0.0106 - acc: 0.9965 - val_loss: 0.1323 - val_acc: 0.9726\n",
            "Epoch 18/20\n",
            " - 3s - loss: 0.0131 - acc: 0.9960 - val_loss: 0.1479 - val_acc: 0.9731\n",
            "Epoch 19/20\n",
            " - 3s - loss: 0.0115 - acc: 0.9968 - val_loss: 0.1374 - val_acc: 0.9757\n",
            "Epoch 20/20\n",
            " - 3s - loss: 0.0074 - acc: 0.9980 - val_loss: 0.1335 - val_acc: 0.9742\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sY4ZfxKsTHaq",
        "colab_type": "code",
        "outputId": "260d67a3-7ece-4a59-bb22-a441957ed207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "_, val_acc2a = model2a.evaluate(X_cv, y_cv)\n",
        "print (val_acc2a)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8400/8400 [==============================] - 0s 58us/step\n",
            "0.9741666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvB_T9T_J0Xi",
        "colab_type": "text"
      },
      "source": [
        "<font color=green size=5>\n",
        "  Model 2B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0pMcQCyJew4",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "Inp = Input(shape=(784,))\n",
        "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
        "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
        "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
        "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
        "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)\n",
        "\n",
        "learning_rate = 0.5\n",
        "adam = keras.optimizers.Adam(lr=learning_rate)\n",
        "model2b = Model(Inp, output)\n",
        "\n",
        "model2b.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyGCf3FWJ5DP",
        "colab_type": "code",
        "outputId": "8d1c8804-8aa9-410a-9b2b-30016e7ab641",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "history2b = model2b.fit(X_train, y_train,\n",
        "                        batch_size = batch_size,\n",
        "                        epochs = training_epochs,\n",
        "                            validation_data=(X_cv, y_cv))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 33600 samples, validate on 8400 samples\n",
            "Epoch 1/20\n",
            "33600/33600 [==============================] - 3s 99us/step - loss: 0.3434 - acc: 0.8972 - val_loss: 0.1776 - val_acc: 0.9481\n",
            "Epoch 2/20\n",
            "33600/33600 [==============================] - 3s 81us/step - loss: 0.1239 - acc: 0.9624 - val_loss: 0.1194 - val_acc: 0.9623\n",
            "Epoch 3/20\n",
            "33600/33600 [==============================] - 3s 85us/step - loss: 0.0826 - acc: 0.9743 - val_loss: 0.1229 - val_acc: 0.9613\n",
            "Epoch 4/20\n",
            "33600/33600 [==============================] - 3s 89us/step - loss: 0.0579 - acc: 0.9821 - val_loss: 0.1191 - val_acc: 0.9637\n",
            "Epoch 5/20\n",
            "33600/33600 [==============================] - 3s 88us/step - loss: 0.0473 - acc: 0.9842 - val_loss: 0.0917 - val_acc: 0.9711\n",
            "Epoch 6/20\n",
            "33600/33600 [==============================] - 3s 87us/step - loss: 0.0340 - acc: 0.9894 - val_loss: 0.1101 - val_acc: 0.9682\n",
            "Epoch 7/20\n",
            "33600/33600 [==============================] - 3s 88us/step - loss: 0.0338 - acc: 0.9888 - val_loss: 0.1098 - val_acc: 0.9682\n",
            "Epoch 8/20\n",
            "33600/33600 [==============================] - 3s 81us/step - loss: 0.0245 - acc: 0.9926 - val_loss: 0.1041 - val_acc: 0.9729\n",
            "Epoch 9/20\n",
            "33600/33600 [==============================] - 3s 85us/step - loss: 0.0245 - acc: 0.9921 - val_loss: 0.1037 - val_acc: 0.9740\n",
            "Epoch 10/20\n",
            "33600/33600 [==============================] - 3s 82us/step - loss: 0.0234 - acc: 0.9919 - val_loss: 0.1191 - val_acc: 0.9702\n",
            "Epoch 11/20\n",
            "33600/33600 [==============================] - 3s 81us/step - loss: 0.0188 - acc: 0.9936 - val_loss: 0.1214 - val_acc: 0.9729\n",
            "Epoch 12/20\n",
            "33600/33600 [==============================] - 3s 82us/step - loss: 0.0192 - acc: 0.9934 - val_loss: 0.1296 - val_acc: 0.9677\n",
            "Epoch 13/20\n",
            "33600/33600 [==============================] - 3s 80us/step - loss: 0.0166 - acc: 0.9947 - val_loss: 0.1211 - val_acc: 0.9735\n",
            "Epoch 14/20\n",
            "33600/33600 [==============================] - 3s 83us/step - loss: 0.0125 - acc: 0.9962 - val_loss: 0.1244 - val_acc: 0.9733\n",
            "Epoch 15/20\n",
            "33600/33600 [==============================] - 3s 84us/step - loss: 0.0116 - acc: 0.9965 - val_loss: 0.1445 - val_acc: 0.9706\n",
            "Epoch 16/20\n",
            "33600/33600 [==============================] - 3s 83us/step - loss: 0.0209 - acc: 0.9938 - val_loss: 0.1155 - val_acc: 0.9752\n",
            "Epoch 17/20\n",
            "33600/33600 [==============================] - 3s 81us/step - loss: 0.0106 - acc: 0.9964 - val_loss: 0.1295 - val_acc: 0.9727\n",
            "Epoch 18/20\n",
            "33600/33600 [==============================] - 3s 82us/step - loss: 0.0077 - acc: 0.9976 - val_loss: 0.1240 - val_acc: 0.9773\n",
            "Epoch 19/20\n",
            "33600/33600 [==============================] - 3s 81us/step - loss: 0.0170 - acc: 0.9947 - val_loss: 0.1327 - val_acc: 0.9721\n",
            "Epoch 20/20\n",
            "33600/33600 [==============================] - 3s 82us/step - loss: 0.0116 - acc: 0.9966 - val_loss: 0.1214 - val_acc: 0.9737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HfVuhPTfTHa5",
        "colab_type": "code",
        "outputId": "1fd247f3-62c2-49ab-87fd-7cebbce65b35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "_, val_acc2b = model2b.evaluate(X_cv, y_cv)\n",
        "print (val_acc2b)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8400/8400 [==============================] - 0s 59us/step\n",
            "0.9736904761904762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ailqmuwlKQPM",
        "colab_type": "text"
      },
      "source": [
        "<font color=red size = 4> \n",
        "  The accuracy, as measured by the 3 different learning rates 0.01, 0.1 and 0.5 are around 98%, 97% and 98% respectively. As there are no considerable gains by changing the learning rates, we stick with the default learning rate of 0.01.\n",
        "<br><font color=brown size = 4> <br>\n",
        "We proceed to fit a neural network with 5 hidden layers with the features in the hidden layer set as (300, 100, 100, 100, 200) respectively. To ensure that the two models are comparable, we will set the training epochs as 20, and the training batch size as 100."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTH2fON4J7Wy",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "# Input Parameters\n",
        "n_input = 784 # number of features\n",
        "n_hidden_1 = 300\n",
        "n_hidden_2 = 100\n",
        "n_hidden_3 = 100\n",
        "n_hidden_4 = 100\n",
        "n_hidden_5 = 200\n",
        "num_digits = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEF8bTTTKd_6",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "Inp = Input(shape=(784,))\n",
        "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
        "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
        "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
        "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
        "x = Dense(n_hidden_5, activation='relu', name = \"Hidden_Layer_5\")(x)\n",
        "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU5pX0dBKgjA",
        "colab_type": "code",
        "outputId": "f0469ea7-f0e9-44ac-d5b2-88a52e2b00d7",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# Our model would have '7' layers - input layer, 5 hidden layer and 1 output layer\n",
        "model3 = Model(Inp, output)\n",
        "model3.summary() # We have 308,010 parameters to estimate"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "Hidden_Layer_1 (Dense)       (None, 300)               235500    \n",
            "_________________________________________________________________\n",
            "Hidden_Layer_2 (Dense)       (None, 100)               30100     \n",
            "_________________________________________________________________\n",
            "Hidden_Layer_3 (Dense)       (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "Hidden_Layer_4 (Dense)       (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "Hidden_Layer_5 (Dense)       (None, 200)               20200     \n",
            "_________________________________________________________________\n",
            "Output_Layer (Dense)         (None, 10)                2010      \n",
            "=================================================================\n",
            "Total params: 308,010\n",
            "Trainable params: 308,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXNwm2PWKkST",
        "colab_type": "code",
        "outputId": "a38e299e-826d-41dc-bff6-ff3c956c2467",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "# We rely on 'Adam' as our optimizing methodology\n",
        "adam = keras.optimizers.Adam(lr=0.01)\n",
        "\n",
        "model3.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history3 = model3.fit(X_train, y_train,\n",
        "                      batch_size = batch_size,\n",
        "                      epochs = training_epochs,\n",
        "                      validation_data=(X_cv, y_cv))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 33600 samples, validate on 8400 samples\n",
            "Epoch 1/20\n",
            "33600/33600 [==============================] - 4s 107us/step - loss: 0.3581 - acc: 0.8898 - val_loss: 0.1675 - val_acc: 0.9495\n",
            "Epoch 2/20\n",
            "33600/33600 [==============================] - 3s 86us/step - loss: 0.1235 - acc: 0.9616 - val_loss: 0.1196 - val_acc: 0.9626\n",
            "Epoch 3/20\n",
            "33600/33600 [==============================] - 3s 87us/step - loss: 0.0847 - acc: 0.9729 - val_loss: 0.1075 - val_acc: 0.9686\n",
            "Epoch 4/20\n",
            "33600/33600 [==============================] - 3s 87us/step - loss: 0.0642 - acc: 0.9796 - val_loss: 0.1213 - val_acc: 0.9651\n",
            "Epoch 5/20\n",
            "33600/33600 [==============================] - 3s 87us/step - loss: 0.0453 - acc: 0.9864 - val_loss: 0.1049 - val_acc: 0.9705\n",
            "Epoch 6/20\n",
            "33600/33600 [==============================] - 3s 86us/step - loss: 0.0395 - acc: 0.9867 - val_loss: 0.1120 - val_acc: 0.9688\n",
            "Epoch 7/20\n",
            "33600/33600 [==============================] - 3s 87us/step - loss: 0.0320 - acc: 0.9893 - val_loss: 0.1271 - val_acc: 0.9676\n",
            "Epoch 8/20\n",
            "33600/33600 [==============================] - 3s 87us/step - loss: 0.0296 - acc: 0.9906 - val_loss: 0.1059 - val_acc: 0.9723\n",
            "Epoch 9/20\n",
            "33600/33600 [==============================] - 3s 89us/step - loss: 0.0272 - acc: 0.9910 - val_loss: 0.1291 - val_acc: 0.9688\n",
            "Epoch 10/20\n",
            "33600/33600 [==============================] - 3s 86us/step - loss: 0.0237 - acc: 0.9926 - val_loss: 0.1091 - val_acc: 0.9721\n",
            "Epoch 11/20\n",
            "33600/33600 [==============================] - 3s 86us/step - loss: 0.0220 - acc: 0.9926 - val_loss: 0.1107 - val_acc: 0.9737\n",
            "Epoch 12/20\n",
            "33600/33600 [==============================] - 3s 85us/step - loss: 0.0144 - acc: 0.9959 - val_loss: 0.1404 - val_acc: 0.9714\n",
            "Epoch 13/20\n",
            "33600/33600 [==============================] - 3s 86us/step - loss: 0.0199 - acc: 0.9938 - val_loss: 0.1317 - val_acc: 0.9723\n",
            "Epoch 14/20\n",
            "33600/33600 [==============================] - 3s 88us/step - loss: 0.0174 - acc: 0.9946 - val_loss: 0.1358 - val_acc: 0.9707\n",
            "Epoch 15/20\n",
            "33600/33600 [==============================] - 3s 85us/step - loss: 0.0202 - acc: 0.9935 - val_loss: 0.1088 - val_acc: 0.9750\n",
            "Epoch 16/20\n",
            "33600/33600 [==============================] - 3s 87us/step - loss: 0.0179 - acc: 0.9942 - val_loss: 0.1242 - val_acc: 0.9718\n",
            "Epoch 17/20\n",
            "33600/33600 [==============================] - 3s 87us/step - loss: 0.0097 - acc: 0.9970 - val_loss: 0.1394 - val_acc: 0.9715\n",
            "Epoch 18/20\n",
            "33600/33600 [==============================] - 3s 86us/step - loss: 0.0157 - acc: 0.9951 - val_loss: 0.1350 - val_acc: 0.9713\n",
            "Epoch 19/20\n",
            "33600/33600 [==============================] - 3s 85us/step - loss: 0.0138 - acc: 0.9958 - val_loss: 0.1434 - val_acc: 0.9723\n",
            "Epoch 20/20\n",
            "33600/33600 [==============================] - 3s 87us/step - loss: 0.0122 - acc: 0.9966 - val_loss: 0.1174 - val_acc: 0.9757\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jLQrK_tETHbR",
        "colab_type": "code",
        "outputId": "abb5031f-030c-4f84-dc9b-36a3bdd28d27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "_, val_acc3 = model3.evaluate(X_cv, y_cv)\n",
        "print (val_acc3)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8400/8400 [==============================] - 1s 64us/step\n",
            "0.9757142857142858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8x2f7iYLCdf",
        "colab_type": "text"
      },
      "source": [
        "<font color=red size=4>\n",
        "  ompared to our first model, adding an additional layer did not significantly improve the accuracy from our previous model. However, there are computational costs (in terms of complexity) in implementing an additional layer in our neural network. Given that the benefits of an additional layer are low while the costs are high, we will stick with the 4 layer neural network.\n",
        "<br><font color=brown size=4><br>\n",
        "We now proceed to include dropout (dropout rate of 0.3) in our second model to prevent overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS07K9S-KqjR",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "# Input Parameters\n",
        "n_input = 784 # number of features\n",
        "n_hidden_1 = 300\n",
        "n_hidden_2 = 100\n",
        "n_hidden_3 = 100\n",
        "n_hidden_4 = 200\n",
        "num_digits = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCtEE5x-LLpX",
        "colab_type": "code",
        "trusted": true,
        "outputId": "a4c3adbd-4bbc-4d82-9f39-e7bcb48154fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "Inp = Input(shape=(784,))\n",
        "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
        "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fppJBSlXLQUr",
        "colab_type": "code",
        "outputId": "1fd92296-8190-468f-ff9c-5a4111191877",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# Our model would have '6' layers - input layer, 4 hidden layer and 1 output layer\n",
        "model4 = Model(Inp, output)\n",
        "model4.summary() # We have 297,910 parameters to estimate"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "Hidden_Layer_1 (Dense)       (None, 300)               235500    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "Hidden_Layer_2 (Dense)       (None, 100)               30100     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "Hidden_Layer_3 (Dense)       (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "Hidden_Layer_4 (Dense)       (None, 200)               20200     \n",
            "_________________________________________________________________\n",
            "Output_Layer (Dense)         (None, 10)                2010      \n",
            "=================================================================\n",
            "Total params: 297,910\n",
            "Trainable params: 297,910\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxKXVDGvLVs4",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "model4.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDHcl0fRLbqI",
        "colab_type": "code",
        "outputId": "11502fbe-8852-4034-958e-29b69a74702e",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "history = model4.fit(X_train, y_train,\n",
        "                    batch_size = batch_size,\n",
        "                    epochs = training_epochs,\n",
        "                    validation_data=(X_cv, y_cv))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 33600 samples, validate on 8400 samples\n",
            "Epoch 1/20\n",
            "33600/33600 [==============================] - 4s 109us/step - loss: 0.5755 - acc: 0.8164 - val_loss: 0.1982 - val_acc: 0.9418\n",
            "Epoch 2/20\n",
            "33600/33600 [==============================] - 3s 88us/step - loss: 0.2225 - acc: 0.9349 - val_loss: 0.1555 - val_acc: 0.9561\n",
            "Epoch 3/20\n",
            "33600/33600 [==============================] - 3s 88us/step - loss: 0.1715 - acc: 0.9508 - val_loss: 0.1376 - val_acc: 0.9599\n",
            "Epoch 4/20\n",
            "33600/33600 [==============================] - 3s 88us/step - loss: 0.1363 - acc: 0.9606 - val_loss: 0.1233 - val_acc: 0.9656\n",
            "Epoch 5/20\n",
            "33600/33600 [==============================] - 3s 88us/step - loss: 0.1195 - acc: 0.9653 - val_loss: 0.1153 - val_acc: 0.9669\n",
            "Epoch 6/20\n",
            "33600/33600 [==============================] - 3s 89us/step - loss: 0.1061 - acc: 0.9685 - val_loss: 0.1036 - val_acc: 0.9707\n",
            "Epoch 7/20\n",
            "33600/33600 [==============================] - 3s 88us/step - loss: 0.0953 - acc: 0.9720 - val_loss: 0.1086 - val_acc: 0.9704\n",
            "Epoch 8/20\n",
            "33600/33600 [==============================] - 3s 88us/step - loss: 0.0868 - acc: 0.9740 - val_loss: 0.1013 - val_acc: 0.9715\n",
            "Epoch 9/20\n",
            "33600/33600 [==============================] - 3s 88us/step - loss: 0.0807 - acc: 0.9763 - val_loss: 0.0978 - val_acc: 0.9748\n",
            "Epoch 10/20\n",
            "33600/33600 [==============================] - 3s 88us/step - loss: 0.0738 - acc: 0.9774 - val_loss: 0.0936 - val_acc: 0.9765\n",
            "Epoch 11/20\n",
            "33600/33600 [==============================] - 3s 87us/step - loss: 0.0683 - acc: 0.9796 - val_loss: 0.0938 - val_acc: 0.9743\n",
            "Epoch 12/20\n",
            "33600/33600 [==============================] - 3s 89us/step - loss: 0.0645 - acc: 0.9808 - val_loss: 0.0899 - val_acc: 0.9757\n",
            "Epoch 13/20\n",
            "33600/33600 [==============================] - 3s 89us/step - loss: 0.0598 - acc: 0.9824 - val_loss: 0.1024 - val_acc: 0.9758\n",
            "Epoch 14/20\n",
            "33600/33600 [==============================] - 3s 87us/step - loss: 0.0613 - acc: 0.9818 - val_loss: 0.0869 - val_acc: 0.9775\n",
            "Epoch 15/20\n",
            "33600/33600 [==============================] - 3s 88us/step - loss: 0.0552 - acc: 0.9836 - val_loss: 0.0919 - val_acc: 0.9758\n",
            "Epoch 16/20\n",
            "33600/33600 [==============================] - 3s 87us/step - loss: 0.0534 - acc: 0.9845 - val_loss: 0.0966 - val_acc: 0.9756\n",
            "Epoch 17/20\n",
            "33600/33600 [==============================] - 3s 88us/step - loss: 0.0514 - acc: 0.9843 - val_loss: 0.0973 - val_acc: 0.9765\n",
            "Epoch 18/20\n",
            "33600/33600 [==============================] - 3s 86us/step - loss: 0.0496 - acc: 0.9857 - val_loss: 0.0956 - val_acc: 0.9762\n",
            "Epoch 19/20\n",
            "33600/33600 [==============================] - 3s 88us/step - loss: 0.0481 - acc: 0.9854 - val_loss: 0.0838 - val_acc: 0.9780\n",
            "Epoch 20/20\n",
            "33600/33600 [==============================] - 3s 88us/step - loss: 0.0419 - acc: 0.9873 - val_loss: 0.0862 - val_acc: 0.9786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6sstp6wsTHbv",
        "colab_type": "code",
        "outputId": "d1fdd8ac-1bc5-4471-9340-8ea9354d6958",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "_, val_acc4 = model4.evaluate(X_cv, y_cv)\n",
        "print (val_acc4)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8400/8400 [==============================] - 1s 67us/step\n",
            "0.9785714285714285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BePIvOcvTHb0",
        "colab_type": "code",
        "outputId": "9b559fcf-0c18-47df-cd2b-1c80e89490ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "eval_model = pd.DataFrame({\n",
        "\"Model\": ['Model', 'Model2', 'Model2a', 'Model2b', 'Model3', 'Model4'],\n",
        "    \"Validation Accuracy\" : [val_acc1, val_acc2, val_acc2a, val_acc2b, val_acc3, val_acc4]\n",
        "   })\n",
        "\n",
        "eval_model.sort_values(by = 'Validation Accuracy', ascending=False)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Validation Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Model4</td>\n",
              "      <td>0.978571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Model3</td>\n",
              "      <td>0.975714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Model2a</td>\n",
              "      <td>0.974167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Model2b</td>\n",
              "      <td>0.973690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Model2</td>\n",
              "      <td>0.971071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Model</td>\n",
              "      <td>0.959048</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Model  Validation Accuracy\n",
              "5   Model4             0.978571\n",
              "4   Model3             0.975714\n",
              "2  Model2a             0.974167\n",
              "3  Model2b             0.973690\n",
              "1   Model2             0.971071\n",
              "0    Model             0.959048"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBYN9lEdQe8K",
        "colab_type": "text"
      },
      "source": [
        "<font color=green size = 6> \n",
        "  With a validation score of close to 98%, we proceed to use this model to predict for the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3QrvG_0Lde5",
        "colab_type": "code",
        "outputId": "30e0ab48-10ad-447f-854c-373ef3ccd2b0",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_pred = pd.DataFrame(model4.predict(X_test, batch_size=200))\n",
        "test_pred = pd.DataFrame(test_pred.idxmax(axis = 1))\n",
        "test_pred.index.name = 'ImageId'\n",
        "test_pred = test_pred.rename(columns = {0: 'Label'}).reset_index()\n",
        "test_pred['ImageId'] = test_pred['ImageId'] + 1\n",
        "\n",
        "test_pred.head()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ImageId  Label\n",
              "0        1      2\n",
              "1        2      0\n",
              "2        3      9\n",
              "3        4      9\n",
              "4        5      3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNSxDrhXQk1w",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "#test_pred.to_csv('kaggle_mnist_digits_submission.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ls9daBhyTHcA",
        "colab_type": "text"
      },
      "source": [
        "<font color=brown size=5> \n",
        "In the above example,  we read the numeric data of pixels to identify Digits. Now, we will read images and use CNN to identify if the input and classify it as one of the 10 fashion items.<br>\n",
        "A convolutional neural network (CNN) is a neural network that can “see ” a subset of the data. It can detect a pattern in images better than perceptron.\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcFfMtJnQ99S",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "# Import MNIST dataset which is already in Keras\n",
        "\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Import the Libraries\n",
        "\n",
        "#Same as ANN\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Related to CNN\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPool2D\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "#Same ANN Model\n",
        "from keras.layers import Dense\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3QXvx_3mfbc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c1c42ca8-2ecd-40c9-fd57-ed735ecb678c"
      },
      "source": [
        "# Get data\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "print('Training data shape : ', X_train.shape, y_train.shape)\n",
        "print ('Test Shape ',  X_test.shape, y_test.shape)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape :  (60000, 28, 28) (60000,)\n",
            "Test Shape  (10000, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtF4s6osmtCL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e0a23b6c-6b2e-4fc2-9d48-4b5f2e42a40c"
      },
      "source": [
        "# Find the unique numbers from the train labels\n",
        "classes = np.unique(y_train)\n",
        "nClasses = len(classes)\n",
        "print('Total number of outputs : ', nClasses)\n",
        "print('Output classes : ', classes)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of outputs :  10\n",
            "Output classes :  [0 1 2 3 4 5 6 7 8 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XG4cyrwm3H-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "46297a42-defc-481f-97b7-13b0511e8d59"
      },
      "source": [
        "plt.figure(figsize=[5, 5])\n",
        "\n",
        "#Display first image in training data\n",
        "plt.subplot(121)\n",
        "plt.imshow(X_train[0,:,:], cmap='gray')\n",
        "plt.title(\"Ground Truth : {}\".format(y_train[0]))\n",
        "\n",
        "# Display the first image in testing data\n",
        "plt.subplot(122)\n",
        "plt.imshow(X_test[0,:,:], cmap='gray')\n",
        "plt.title(\"Ground Truth : {}\".format(y_test[0]))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Ground Truth : 9')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATwAAACuCAYAAACr3LH6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 360x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHfXlarQn61D",
        "colab_type": "text"
      },
      "source": [
        "<font color=brown size=4>\n",
        "The image looks like an Ankle boot and Class assigned is 9. Similarly, other fashion items will have different Class. \n",
        "<br>\n",
        "<font color=blue size=4>\n",
        "As each image has dimension of 28 x 28, it has to be converted to 28 x 28 x 1 (3D) format. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eoJMO03UTHcI",
        "colab_type": "code",
        "outputId": "58b61a5a-a551-4a69-edbc-a16a0251c288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_train = X_train.reshape(-1, 28,28, 1)\n",
        "X_test = X_test.reshape(-1, 28,28, 1)\n",
        "print ('Training datasets shapes', X_train.shape, X_test.shape)\n",
        "\n",
        "X_train.dtype"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training datasets shapes (60000, 28, 28, 1) (10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCLS781MgWb7",
        "colab_type": "text"
      },
      "source": [
        "CNN reads our images as is and hence flattening is not required. \n",
        "If you check your x_train, you will have 60,000 x 28 x 28 x 1 data. \n",
        "The data CNN needs to read must be like this: total_data x width x height x channels.\n",
        "Height and width are self-explanatory. Channels are like Red or Green or Blue in RGB images. In RGB, because there are three channels, we need to make the data x 3. But because we work with grayscale images, every value on Red, Green, or Blue channel is the same and we reduce to one channel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTWNYJFrpY2e",
        "colab_type": "text"
      },
      "source": [
        "<font color=brown size=4> \n",
        "Right now data is in unit8 format. This is to be converted to float32.  Also, have to rescale the pixels values in 0 to 255 range.\n",
        "<br>\n",
        "<font color=blue size=4> \n",
        "The label field is in categorical form at present 0-9. This field needs to be one-hot encolded. For instance, Class 9 that denotes Ankle Boot after One-Hot encoded, it will be converted to [0 0 0 0 0 0 0 0 0 1], where in each is a new feature added to the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOYn1_FXpGcq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3d1588fa-997e-41af-d799-c90db45abde4"
      },
      "source": [
        "# Change the labels from categorical to one-hot encoding\n",
        "y_train_one_hot = to_categorical(y_train)\n",
        "y_test_one_hot = to_categorical(y_test)\n",
        "\n",
        "# Display the change for category label using one-hot encoding\n",
        "print('Original label:', y_train[0])\n",
        "print('After conversion to one-hot:', y_train_one_hot[0])"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original label: 9\n",
            "After conversion to one-hot: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K17hM0PsEKP",
        "colab_type": "text"
      },
      "source": [
        "Split the Training data now to set aside somed data for Validation. This is a good practice. we will use 20% of the Training data for validation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6HqCf1NsDTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_valid,label_train,label_valid = train_test_split(X_train, y_train_one_hot, test_size=0.2, random_state=13)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2a3I08zs3aT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9e84dae-88fd-401d-9005-0c69fc023da7"
      },
      "source": [
        "# Check the Shapes of the Train and  Validation Datasets\n",
        "X_train.shape,X_valid.shape,label_train.shape, label_valid.shape"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((48000, 28, 28, 1), (12000, 28, 28, 1), (48000, 10), (12000, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSqgBxjhteLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# these were not included earlier but now will add these to use for better performance\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD0EP3QYtuaX",
        "colab_type": "text"
      },
      "source": [
        "The Model Architecture will have \n",
        "1. The first layer will have 32-3 x 3 filters,\n",
        "2. The second layer will have 64-3 x 3 filters and\n",
        "3. The third layer will have 128-3 x 3 filters.\n",
        "4. In addition, there are three max-pooling layers each of size 2 x 2.\n",
        "\n",
        "In Keras we can just stack up layers by adding desired layers one by one. We will start with Conv2D layer as we are handling images. \n",
        "We will make use to LeakyReLU activation function (instead of regular ReLU) as this function which helps the network to learn non-linear decision boundaries. There are 10 Classes and hence need non-linear decision boundary that could separate these 10 classes that are not linearly separable. Also, LeakyReLU works against dying neurons which is typically the cases in Convolutional NNs. This has been found effective as against the Logistic Sigmoid Function. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcUJeaWRwRT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_model = Sequential()\n",
        "fashion_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(28,28,1),padding='same'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.1))\n",
        "fashion_model.add(MaxPooling2D((2, 2),padding='same'))\n",
        "fashion_model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.1))\n",
        "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "fashion_model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.1))                  \n",
        "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "fashion_model.add(Flatten())\n",
        "fashion_model.add(Dense(128, activation='linear'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.1))                  \n",
        "fashion_model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9JAQpgfgTHci",
        "colab_type": "code",
        "outputId": "57dd0b2e-299b-4315-fc46-a4ef40f41c3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "fashion_model.summary()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 356,234\n",
            "Trainable params: 356,234\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufgdW7SKiFxL",
        "colab_type": "text"
      },
      "source": [
        "<font color=brown size=3> \n",
        "1. Conv2d changed 28x28x1 image to 28x28x32, 28x28x64 and 28x28x128 respectively layers. These 32, 64 and 128 are like hidden layer cells.\n",
        "2. MaxPooling2D reduces the width and height so that you will not need to compute all the cells. It reduces the size to 14x14x32 and further reduced to 7x7x64 and further to 4x4x128 in their respective layers. \n",
        "3. Flatten just flattens out the output of last MaxPooling into a hidden layer of 2048 cells\n",
        "\n",
        "\n",
        "<font color=blue size=4> \n",
        "Compiling the model using Adam Optimizer which is by far found to be effective optimization algorithm. \n",
        "Loss type is \"Categorical Cross Entropy\" which is used for multi-class classification. Alternatively \"Binary Cross Entropy\" can also be used but that works better for \"Binary Classifications\". While compiling the model, we gather Accuracy Metrics that can be used for model evaluation. \n",
        "\n",
        "After compilation, we will set parameters for Training and start the training process. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUgUSINWyUUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-FJor86RMed",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 20\n",
        "num_classes = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Re8Ta8-XTHco",
        "colab_type": "code",
        "outputId": "cb7ec441-64a0-4291-b757-6092f9270cd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "fashion_train = fashion_model.fit(X_train, label_train, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(X_valid, label_valid))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 13s 270us/step - loss: 0.4614 - acc: 0.8327 - val_loss: 0.3249 - val_acc: 0.8805\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 12s 245us/step - loss: 0.2894 - acc: 0.8940 - val_loss: 0.2874 - val_acc: 0.8929\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 12s 243us/step - loss: 0.2406 - acc: 0.9118 - val_loss: 0.2483 - val_acc: 0.9109\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 12s 244us/step - loss: 0.2072 - acc: 0.9244 - val_loss: 0.2317 - val_acc: 0.9158\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 12s 247us/step - loss: 0.1827 - acc: 0.9331 - val_loss: 0.2398 - val_acc: 0.9128\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 12s 248us/step - loss: 0.1581 - acc: 0.9422 - val_loss: 0.2388 - val_acc: 0.9153\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 12s 246us/step - loss: 0.1396 - acc: 0.9484 - val_loss: 0.2297 - val_acc: 0.9200\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 12s 244us/step - loss: 0.1192 - acc: 0.9562 - val_loss: 0.2405 - val_acc: 0.9206\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 12s 246us/step - loss: 0.1029 - acc: 0.9617 - val_loss: 0.2554 - val_acc: 0.9179\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 12s 243us/step - loss: 0.0871 - acc: 0.9672 - val_loss: 0.2964 - val_acc: 0.9107\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 12s 244us/step - loss: 0.0729 - acc: 0.9728 - val_loss: 0.3126 - val_acc: 0.9156\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 11s 239us/step - loss: 0.0635 - acc: 0.9760 - val_loss: 0.2840 - val_acc: 0.9202\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 11s 239us/step - loss: 0.0551 - acc: 0.9800 - val_loss: 0.3454 - val_acc: 0.9196\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 11s 239us/step - loss: 0.0478 - acc: 0.9826 - val_loss: 0.3697 - val_acc: 0.9124\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 11s 238us/step - loss: 0.0441 - acc: 0.9836 - val_loss: 0.3827 - val_acc: 0.9143\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 11s 239us/step - loss: 0.0363 - acc: 0.9868 - val_loss: 0.3978 - val_acc: 0.9171\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 11s 239us/step - loss: 0.0380 - acc: 0.9855 - val_loss: 0.3883 - val_acc: 0.9203\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 11s 237us/step - loss: 0.0333 - acc: 0.9879 - val_loss: 0.4017 - val_acc: 0.9174\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 11s 239us/step - loss: 0.0337 - acc: 0.9879 - val_loss: 0.4251 - val_acc: 0.9188\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 11s 239us/step - loss: 0.0300 - acc: 0.9890 - val_loss: 0.4300 - val_acc: 0.9197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp2pUHERjKK2",
        "colab_type": "text"
      },
      "source": [
        "<font color=brown size=4>\n",
        "Training Accuracy is good at almost 99% but it is expected to be good. We should only be looking at Validation Accuracy and Validation Loss. Validation Accuracy is almost 92% which is good but <font color=red size=4> Validation Loss is 43% which is very high and could mean that its due to overfitting.\n",
        "<br> <font color=brown size=4>\n",
        "Loss  needs to be brought down as much as possible by using drop-out layer (purposefully omitts few neuros so that the model will not overlearn (overfitting) in subsequent Training trails. For now, lets get the evaluation of this model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ddXN5yzaTHct",
        "colab_type": "code",
        "outputId": "30209fe8-ba05-4f81-bfb4-1b7b3e9b2c0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_eval = fashion_model.evaluate(X_test, y_test_one_hot, verbose=0)\n",
        "\n",
        "print('Test loss:', test_eval[0])\n",
        "print('Test accuracy:', test_eval[1])"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.4463336690051016\n",
            "Test accuracy: 0.9151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_G1MeBh4W3b",
        "colab_type": "text"
      },
      "source": [
        "Let's put your model evaluation into perspective and plot the accuracy and loss plots between training and validation data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mQQUkmu4YQy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "230cfd3f-97ca-4b1d-c864-03830168925a"
      },
      "source": [
        "accuracy = fashion_train.history['acc']\n",
        "val_accuracy = fashion_train.history['val_acc']\n",
        "loss = fashion_train.history['loss']\n",
        "val_loss = fashion_train.history['val_loss']\n",
        "epochs = range(len(accuracy))\n",
        "plt.figure(figsize=[10,5])\n",
        "plt.subplot(121)\n",
        "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy', color='red' )\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss', color='red' )\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl0AAAE/CAYAAAB8VnbnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npZRSygL/AyTM3LIGJEN2AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olzln_9s6Iqi",
        "colab_type": "text"
      },
      "source": [
        "<font color=brown size=3> Point to Note from the Above plots is that, \n",
        "<font color=red size=3>\n",
        "Validation Accuracy more or less hovered around the same accuracy after 3-4 epochs. It did increase linearly with validation loss but did not continue the trend after 3-4 epochs. This means that after 3-4 epochs model started memorizing the data. \n",
        "<font color=brown size=3>\n",
        "Time to introduce Dropout layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xv8vniAjsD7",
        "colab_type": "code",
        "outputId": "c34b61cd-a153-4cf4-e5c2-3e5b8e6d3e8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "fashion_model = Sequential()\n",
        "fashion_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',padding='same',input_shape=(28,28,1)))\n",
        "fashion_model.add(LeakyReLU(alpha=0.1))\n",
        "fashion_model.add(MaxPooling2D((2, 2),padding='same'))\n",
        "fashion_model.add(Dropout(0.25))\n",
        "fashion_model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.1))\n",
        "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "fashion_model.add(Dropout(0.25))\n",
        "fashion_model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.1))                  \n",
        "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "fashion_model.add(Dropout(0.4))\n",
        "fashion_model.add(Flatten())\n",
        "fashion_model.add(Dense(128, activation='linear'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.1))           \n",
        "fashion_model.add(Dropout(0.3))\n",
        "fashion_model.add(Dense(num_classes, activation='softmax'))\n",
        "fashion_model.summary()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_14 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)   (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 356,234\n",
            "Trainable params: 356,234\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdoyMBdJDvDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 20\n",
        "num_classes = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUc3FrtRkLod",
        "colab_type": "code",
        "outputId": "d9e20dbd-56a5-4f98-dee1-c27e041a319f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "fashion_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
        "\n",
        "fashion_train_dropout = fashion_model.fit(X_train, label_train, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(X_valid, label_valid))"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 14s 291us/step - loss: 0.5970 - acc: 0.7771 - val_loss: 0.3612 - val_acc: 0.8640\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 12s 246us/step - loss: 0.3771 - acc: 0.8621 - val_loss: 0.3148 - val_acc: 0.8852\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 12s 242us/step - loss: 0.3279 - acc: 0.8795 - val_loss: 0.2980 - val_acc: 0.8861\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 12s 244us/step - loss: 0.3006 - acc: 0.8892 - val_loss: 0.2698 - val_acc: 0.9016\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 12s 241us/step - loss: 0.2820 - acc: 0.8962 - val_loss: 0.2486 - val_acc: 0.9067\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 12s 243us/step - loss: 0.2653 - acc: 0.9022 - val_loss: 0.2426 - val_acc: 0.9112\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 12s 243us/step - loss: 0.2586 - acc: 0.9035 - val_loss: 0.2377 - val_acc: 0.9116\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 12s 240us/step - loss: 0.2492 - acc: 0.9064 - val_loss: 0.2311 - val_acc: 0.9165\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 11s 239us/step - loss: 0.2454 - acc: 0.9081 - val_loss: 0.2312 - val_acc: 0.9152\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 12s 248us/step - loss: 0.2368 - acc: 0.9113 - val_loss: 0.2281 - val_acc: 0.9175\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 11s 239us/step - loss: 0.2294 - acc: 0.9144 - val_loss: 0.2232 - val_acc: 0.9168\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 11s 238us/step - loss: 0.2251 - acc: 0.9151 - val_loss: 0.2195 - val_acc: 0.9205\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 11s 238us/step - loss: 0.2206 - acc: 0.9171 - val_loss: 0.2264 - val_acc: 0.9177\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 11s 239us/step - loss: 0.2164 - acc: 0.9173 - val_loss: 0.2240 - val_acc: 0.9209\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 11s 238us/step - loss: 0.2127 - acc: 0.9187 - val_loss: 0.2206 - val_acc: 0.9219\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 12s 240us/step - loss: 0.2096 - acc: 0.9217 - val_loss: 0.2196 - val_acc: 0.9200\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 11s 238us/step - loss: 0.2069 - acc: 0.9234 - val_loss: 0.2195 - val_acc: 0.9206\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 11s 238us/step - loss: 0.2040 - acc: 0.9236 - val_loss: 0.2188 - val_acc: 0.9203\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 11s 239us/step - loss: 0.2037 - acc: 0.9235 - val_loss: 0.2133 - val_acc: 0.9261\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 12s 240us/step - loss: 0.1988 - acc: 0.9250 - val_loss: 0.2132 - val_acc: 0.9240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcsrJi8pFOMO",
        "colab_type": "text"
      },
      "source": [
        "<font color=brown size=3>\n",
        "Quick note is that the validation loss has come down by half from 43% to 21%. <br>\n",
        "<font color=brown size=4>\n",
        "Model Evaluation on the Test Set <br>\n",
        "<font color=blue size=4>\n",
        "Finally, let's also evaluate the new model to see how it performs!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHexgWgklZtj",
        "colab_type": "code",
        "outputId": "4cadf637-20f0-415a-8f58-0c6c8a3466ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "test_eval = fashion_model.evaluate(X_test, y_test_one_hot, verbose=1)\n",
        "print('Test loss:', test_eval[0])\n",
        "print('Test accuracy:', test_eval[1])"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 119us/step\n",
            "Test loss: 0.22688650356531143\n",
            "Test accuracy: 0.92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iVLKyLjGv8m",
        "colab_type": "text"
      },
      "source": [
        "<font color=brown size=4>\n",
        "Run the plots for visuialization enabling easy comparison "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSRTCVITud57",
        "colab_type": "code",
        "outputId": "fbb3792f-b6da-4500-f204-8f992c4f88b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "accuracy = fashion_train_dropout.history['acc']\n",
        "val_accuracy = fashion_train_dropout.history['val_acc']\n",
        "loss = fashion_train_dropout.history['loss']\n",
        "val_loss = fashion_train_dropout.history['val_loss']\n",
        "epochs = range(len(accuracy))\n",
        "plt.figure(figsize=[10,5])\n",
        "plt.subplot(121)\n",
        "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy', color='red' )\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss', color='red' )\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl0AAAE/CAYAAAB8VnbnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8oD/B/bPkPB4H2QAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnYt2oI-HzUn",
        "colab_type": "text"
      },
      "source": [
        "<font color=green size=4>\n",
        "We can see that the validation loss and validation accuracy both are in sync with the training loss and training accuracy. Even though the validation loss and accuracy line are not linear, but it shows that this model is not overfitting: the validation loss is decreasing and not increasing, and there is not much gap between training and validation accuracy and infact this model did slight better on Validation loss compared to Training loss. <br>\n",
        "<font color=brown size=5>\n",
        "Will use this model to predict the Original Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2CVSvwItnYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_classes = fashion_model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru7L8LIO4CoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_classes = np.argmax(np.round(predicted_classes),axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UpLsZZlJo_7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5bbd283-3082-459a-87f5-570167502b69"
      },
      "source": [
        "predicted_classes.shape, y_test.shape"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000,), (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pKTtSKjJrhY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "0b5d5ae2-fac2-42af-a791-39fbd860882e"
      },
      "source": [
        "correct = np.where(predicted_classes==y_test)[0]\n",
        "print (\"Found %d correct labels\" % len(correct))\n",
        "for i, correct in enumerate(correct[:9]):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(X_test[correct].reshape(28,28), cmap='gray', interpolation='none')\n",
        "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], y_test[correct]))\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9160 correct labels\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEYCAYAAACUdWs9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAh5r92NJzFo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "a2921c30-4b0a-4584-f88f-bad63d49ee3e"
      },
      "source": [
        "incorrect = np.where(predicted_classes!=y_test)[0]\n",
        "print (\"Found %d incorrect labels\" % len(incorrect))\n",
        "for i, incorrect in enumerate(incorrect[:9]):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(X_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n",
        "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], y_test[incorrect]))\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 840 incorrect labels\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEYCAYAAACUdWs9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gosCwEaQKMCU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "30650d5a-0ce5-403f-fc4b-2f33fbbe19d2"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = [\"Class {}\".format(i) for i in range(num_classes)]\n",
        "print(classification_report(y_test, predicted_classes, target_names=target_names))"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.78      0.90      0.84      1000\n",
            "     Class 1       0.99      0.98      0.99      1000\n",
            "     Class 2       0.85      0.91      0.88      1000\n",
            "     Class 3       0.94      0.90      0.92      1000\n",
            "     Class 4       0.87      0.86      0.87      1000\n",
            "     Class 5       0.99      0.97      0.98      1000\n",
            "     Class 6       0.84      0.71      0.77      1000\n",
            "     Class 7       0.95      0.99      0.97      1000\n",
            "     Class 8       0.99      0.98      0.99      1000\n",
            "     Class 9       0.98      0.95      0.97      1000\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZhggWDXLbfH",
        "colab_type": "text"
      },
      "source": [
        "<font color=red size=4>\n",
        "One can see that the classifier is underperforming for class 6 regarding both precision and recall. For class 0 and class 2, the classifier is lacking precision. Also, for class 4, the classifier is slightly lacking both precision and recall."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFGhv49XLKY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
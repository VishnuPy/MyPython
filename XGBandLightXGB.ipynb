{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XGBandLightXGB.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VishnuPy/MyPython/blob/master/XGBandLightXGB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VbkxM2V2dLr",
        "colab_type": "code",
        "outputId": "2acf2c82-8b2f-42ed-c683-027d77062f86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive\n",
        "%ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive\n",
            "\u001b[0m\u001b[01;34m'My Drive'\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_x3oxRH2p4x",
        "colab_type": "code",
        "outputId": "0836dc06-0d79-46ae-e44c-bc17ab65ba4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "%cd 'My Drive/MyLearning/MLDLAIPython/Data/TextData/'\n",
        "%ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/MyLearning/MLDLAIPython/Data/TextData\n",
            "Adult.csv                          small_tree.dot\n",
            "APPL_Stock_Data_1980thru2019.xlsx  small_tree.png\n",
            "APPL_Stock_Data_2009thru2019.xlsx  temps.csv\n",
            "APPL_Stock_Test_2019_Apr_Jun.xlsx  titanic_test.csv\n",
            "bank-additional-full.csv           titanic_train.csv\n",
            "Bank_Customer_Churn_Modelling.csv  tree.dot\n",
            "breast-cancer-wisconsin-data.csv   tree.png\n",
            "caravan-insurance-challenge.csv    User_Data.csv\n",
            "diabetes.csv                       Wine.csv\n",
            "marks.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgBkZ5VB3Ar4",
        "colab_type": "code",
        "outputId": "9867f285-7501-4795-8045-f6ed61e8acb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "# See https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "  random_image_cpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_cpu = tf.layers.conv2d(random_image_cpu, 32, 7)\n",
        "  net_cpu = tf.reduce_sum(net_cpu)\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "  random_image_gpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_gpu = tf.layers.conv2d(random_image_gpu, 32, 7)\n",
        "  net_gpu = tf.reduce_sum(net_gpu)\n",
        "\n",
        "sess = tf.Session(config=config)\n",
        "\n",
        "# Test execution once to detect errors early.\n",
        "try:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "except tf.errors.InvalidArgumentError:\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise\n",
        "\n",
        "def cpu():\n",
        "  sess.run(net_cpu)\n",
        "  \n",
        "def gpu():\n",
        "  sess.run(net_gpu)\n",
        "  \n",
        "# Runs the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0709 15:25:43.353159 140491279943552 deprecation.py:323] From <ipython-input-3-00b17d59170f>:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "W0709 15:25:43.360304 140491279943552 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "3.7294654230008746\n",
            "GPU (s):\n",
            "0.990456940000513\n",
            "GPU speedup over CPU: 3x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5VLn0aX3H2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing standard libraries \n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "from pandas import Series, DataFrame \n",
        "\n",
        "#import lightgbm and xgboost \n",
        "import lightgbm as lgb \n",
        "import xgboost as xgb \n",
        "\n",
        "#loading our training dataset 'adult.csv' with name 'data' using pandas \n",
        "data=pd.read_csv('Adult.csv',header=None) \n",
        "\n",
        "#Assigning names to the columns \n",
        "data.columns=['age','workclass','fnlwgt','education','education-num','marital_Status','occupation','relationship','race','sex','capital_gain','capital_loss','hours_per_week','native_country','Income'] \n",
        "\n",
        "#glimpse of the dataset \n",
        "data.head() \n",
        "\n",
        "# Label Encoding our target variable \n",
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
        "l=LabelEncoder() \n",
        "l.fit(data.Income) \n",
        "\n",
        "l.classes_ \n",
        "data.Income=Series(l.transform(data.Income))  #label encoding our target variable \n",
        "data.Income.value_counts() \n",
        "\n",
        " \n",
        "\n",
        "#One Hot Encoding of the Categorical features \n",
        "one_hot_workclass=pd.get_dummies(data.workclass) \n",
        "one_hot_education=pd.get_dummies(data.education) \n",
        "one_hot_marital_Status=pd.get_dummies(data.marital_Status) \n",
        "one_hot_occupation=pd.get_dummies(data.occupation)\n",
        "one_hot_relationship=pd.get_dummies(data.relationship) \n",
        "one_hot_race=pd.get_dummies(data.race) \n",
        "one_hot_sex=pd.get_dummies(data.sex) \n",
        "one_hot_native_country=pd.get_dummies(data.native_country) \n",
        "\n",
        "#removing categorical features \n",
        "data.drop(['workclass','education','marital_Status','occupation','relationship','race','sex','native_country'],axis=1,inplace=True) \n",
        "\n",
        " \n",
        "\n",
        "#Merging one hot encoded features with our dataset 'data' \n",
        "data=pd.concat([data,one_hot_workclass,one_hot_education,one_hot_marital_Status,one_hot_occupation,one_hot_relationship,one_hot_race,one_hot_sex,one_hot_native_country],axis=1) \n",
        "\n",
        "#removing dulpicate columns \n",
        "_, i = np.unique(data.columns, return_index=True) \n",
        "data=data.iloc[:, i] \n",
        "\n",
        "#Here our target variable is 'Income' with values as 1 or 0.  \n",
        "#Separating our data into features dataset x and our target dataset y \n",
        "x=data.drop('Income',axis=1) \n",
        "y=data.Income \n",
        "\n",
        " \n",
        "\n",
        "#Imputing missing values in our target variable \n",
        "y.fillna(y.mode()[0],inplace=True) \n",
        "\n",
        "#Now splitting our dataset into test and train \n",
        "from sklearn.model_selection import train_test_split \n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDZnf4FFFWIE",
        "colab_type": "text"
      },
      "source": [
        "<font color=red size=8>\n",
        "  #Applying xgboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi5ttJey4ngl",
        "colab_type": "code",
        "outputId": "aca50c2e-2235-4dc3-f6c6-ae4c2077f4c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#The data is stored in a DMatrix object \n",
        "#label is used to define our outcome variable\n",
        "dtrain=xgb.DMatrix(x_train,label=y_train)\n",
        "dtest=xgb.DMatrix(x_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVUkKp5rFcCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#setting parameters for xgboost\n",
        "parameters={'max_depth':7, 'eta':1, 'silent':1,'objective':'binary:logistic','eval_metric':'auc','learning_rate':.05}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNJUfuM8FhTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training our model \n",
        "num_round=50\n",
        "from datetime import datetime \n",
        "start = datetime.now() \n",
        "xg=xgb.train(parameters,dtrain,num_round) \n",
        "stop = datetime.now()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjTW6W_wFryY",
        "colab_type": "code",
        "outputId": "e8f238a2-6f79-43be-9d63-9a0ac494acc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Execution time of the model \n",
        "execution_time_xgb = stop-start \n",
        "execution_time_xgb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.timedelta(0, 5, 606838)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7niM5w8FwQv",
        "colab_type": "code",
        "outputId": "d8e98a38-5c80-49df-905b-032e4581a131",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#datetime.timedelta( , , ) representation => (days , seconds , microseconds) \n",
        "#now predicting our model on test set \n",
        "ypred=xg.predict(dtest) \n",
        "ypred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.23452379, 0.13591222, 0.07399201, ..., 0.26616085, 0.05969667,\n",
              "       0.04284597], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOtoJ26VGdqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Converting probabilities into 1 or 0  \n",
        "for i in range(0,9769): \n",
        "    if ypred[i]>=.5:       # setting threshold to .5 \n",
        "       ypred[i]=1 \n",
        "    else: \n",
        "       ypred[i]=0 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E14HaOzmGjSt",
        "colab_type": "code",
        "outputId": "276ae52c-864d-4fca-aff6-e72eb6a51dea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#calculating accuracy of our model \n",
        "from sklearn.metrics import accuracy_score \n",
        "accuracy_xgb = accuracy_score(y_test,ypred) \n",
        "accuracy_xgb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8626266762206981"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8e6kvuwGmlr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDL0IH-0G2ef",
        "colab_type": "text"
      },
      "source": [
        "<font color=red size = 8>\n",
        "# Light GBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAuC-BLqG6Wi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data=lgb.Dataset(x_train,label=y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4xN3eN-G_F6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#setting parameters for lightgbm\n",
        "param = {'num_leaves':150, 'objective':'binary','max_depth':7,'learning_rate':.05,'max_bin':200}\n",
        "param['metric'] = ['auc', 'binary_logloss']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sez_-xc3HPcb",
        "colab_type": "text"
      },
      "source": [
        "<font color=green size= 5>\n",
        "  #Here we have set max_depth in xgb and LightGBM to 7 to have a fair comparison between the two."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em2AbWzFHEWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training our model using light gbm\n",
        "num_round=50\n",
        "start=datetime.now()\n",
        "lgbm=lgb.train(param,train_data,num_round)\n",
        "stop=datetime.now()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPzkWchOHWOT",
        "colab_type": "code",
        "outputId": "bf69bf2a-fbee-4a0e-d3b7-903022020cea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Execution time of the model\n",
        "execution_time_lgbm = stop-start\n",
        "execution_time_lgbm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.timedelta(0, 0, 502761)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHg_EZbtHacG",
        "colab_type": "code",
        "outputId": "6e73db66-8904-4a3e-9d21-f95251f45afa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#predicting on test set\n",
        "ypred2=lgbm.predict(x_test)\n",
        "ypred2[0:5]  # showing first 5 predictions"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.20447772, 0.1004021 , 0.05220324, 0.03098052, 0.18028288])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADcZo1n-Hdrz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#converting probabilities into 0 or 1\n",
        "for i in range(0,9769):\n",
        "    if ypred2[i]>=.5:       # setting threshold to .5\n",
        "       ypred2[i]=1\n",
        "    else:  \n",
        "       ypred2[i]=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIhMfCj1HgqV",
        "colab_type": "code",
        "outputId": "f950be87-ec29-4479-8b10-3d005eeb2cd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#calculating accuracy\n",
        "accuracy_lgbm = accuracy_score(ypred2,y_test)\n",
        "accuracy_lgbm\n",
        "y_test.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    7402\n",
              "1    2367\n",
              "Name: Income, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zov40TkKHjCE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2MEcZQyHu4X",
        "colab_type": "code",
        "outputId": "6b9ad99d-6825-410e-d18e-8dd757943ca2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#calculating roc_auc_score for xgboost\n",
        "auc_xgb =  roc_auc_score(y_test,ypred)\n",
        "auc_xgb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7642233963873476"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjbdvVp6HwlR",
        "colab_type": "code",
        "outputId": "d4f41761-695c-4d06-8921-8531eab7d540",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#calculating roc_auc_score for light gbm. \n",
        "auc_lgbm = roc_auc_score(y_test,ypred2)\n",
        "auc_lgbm\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7579194504003132"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv_UfveCHzkL",
        "colab_type": "code",
        "outputId": "f407f2ff-6870-4408-8225-c29d5bd7307e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "#Creating a dataframe ‘comparison_df’ for comparing the performance of Lightgbm and xgb. \n",
        "comparison_df = DataFrame(comparison_dict) \n",
        "comparison_df.index= ['LightGBM','xgboost'] \n",
        "comparison_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy score</th>\n",
              "      <th>auc score</th>\n",
              "      <th>execution time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LightGBM</th>\n",
              "      <td>0.860477</td>\n",
              "      <td>0.757919</td>\n",
              "      <td>00:00:00.502761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>xgboost</th>\n",
              "      <td>0.862627</td>\n",
              "      <td>0.764223</td>\n",
              "      <td>00:00:05.606838</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          accuracy score  auc score  execution time\n",
              "LightGBM        0.860477   0.757919 00:00:00.502761\n",
              "xgboost         0.862627   0.764223 00:00:05.606838"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxxqiZK9YVMZ",
        "colab_type": "text"
      },
      "source": [
        "<font color=green size = 5> \n",
        "There has been only a slight increase in accuracy and auc score by applying Light GBM over XGBOOST but there is a significant difference in the execution time for the training procedure. Light GBM is almost 7 times faster than XGBOOST and is a much better approach when dealing with large datasets.\n",
        "\n",
        "This turns out to be a huge advantage when you are working on large datasets in limited time competitions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvXNPEYoYEUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}